# Installing Surreal
[Install and Run SURREAL Locally](#install-and-run-surreal-locally)  
[Develop Algorithms Locally](#develop-algorithms-locally)  
[Run Surreal on Google Cloud](#run-surreal-on-google-cloud)  
[Setup Custom Docker Build Process](#setup-custom-docker-build-process)  
[Develop Algorithms on Kubernets](#develop-algorithms-on-kubernetes)  
[Develop Surreal on Kubernets](#develop-surreal-on-kubernetes)  
[Reporting Issues](#reporting-issues)  
[Contributing](#contributing)  

---

## Install and Run SURREAL Locally
* Create a python environment. Surreal runs on python 3, we recommend using conda or a virtual environment. For example:
```bash
wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda3-latest-Linux-x86_64.sh 
source ~/.bashrc 
conda create -n surreal python>=3.5
source activate surreal
```

* If you run into issues when installing on Ubuntu, you can check [our docker file](docker/Dockerfile-nvidia).

* Install [pytorch](https://pytorch.org/get-started/locally/).

* Install surreal
(WIP) Surreal is not released yet, see below for instructions
TODO: allow `pip install surreal to work`
```bash
pip install surreal
```

* (Temporary): Install Robotics Suite and Symphony from master branch. Install surreal by `pip install -e .` on branch `refactor4release`.

* Setup `.surreal.yml`. Run the following command to setup the surreal config file at `~/.surreal.yml`. 
```bash
surreal-default-config
```
Then follow [this guide](yaml_config.md) to setup the config file.

* Install environments
You can install RL environments depending on your need. The supported environments are [gym](https://github.com/openai/gym), [DeepMind Control Suite](https://github.com/deepmind/dm_control), and [Surreal Robotics Suite](https://github.com/StanfordVL/MujocoManipulation/tree/refactor4release).
  - TODO(optional): step by step installation commands

* Install Tmux
We use tmux to manage experiments locally. You need to install it if you don't already have it.
On Mac
```bash
brew install tmux
```
On linux
```bash
sudo apt-get install tmux
```

* Create an experiment
You are now ready to create an experiment. Run
```bash
turreal create <experiment_name>
```
If you setup your `.surreal.yml` as default (you need fiels `tmux_preamble_cmds` and `tmux_results_folder` to be properly set), you will see experiment outputs in `~/turreal/experiment_name` and see tensorboard output at `localhost:6006`. You can choose one of the two pre-installed surreal algorithms by using the `--algorithm` flag.
```bash
turreal create --algorithm ppo <experiment_name> # Runs Surreal-PPO
turreal create --algorithm ddpg <experiment_name> # Runs Surreal-DDPG
```
If you have a GPU and installed pytorch with GPU compatibility, you can use 
```
turreal create ... -- --num-gpus 1
```
to use a GPU for learner training.

Use `turreal p` to check the status of each process.
```bash
turreal p
>Group  Name         status  
>       tensorplex   live    
>       learner      live    
>       agent-0      live    
>       loggerplex   live    
>       agent-1      live    
>       tensorboard  live    
>       replay       live    
>       eval-0       live    
>       ps           live  
```

Use `turreal logs` to inspect logs of different components.
```bash
turreal logs learner
> ...
```

You can use `turreal delete` to terminate the experiment.
```bash
turreal delete
> Terminating
```
TODO (optional): more documentation on turreal

## Develop Algorithms Locally
If you want to develop algorithms locally using Surreal. You should create a `my_algorithm.py` file. Run
```bash
turreal create --algorithm <path to my_algorithm.py>
```
to launch your own algorithm. You can refer to [ddpg_configs.py](../) or [ppo_configs.py](../surreal/main/ppo_configs.py) for reference.

## Run SURREAL on Google Cloud
To run large scale experiments, you need to setup Surreal on a kubernetes cluster. Here we provide the guide for Google Cloud.

* Create a google cloud project, follow the guide in [Cloudwise](https://github.com/SurrealAI/cloudwise) to setup the kubernetes cluster. You should be able to verify that your kubectl commandline is connected to a cluster.
```bash
kubectl cluster-info
> Kubernetes master is running at ...
> ...
```

* In the previous step, you will obtain a `<cluster_name>.tf.json` file. This is generated by cloudwise to provide information about the cluster and ease scheduling. You need to provide the path to this file in `.surreal.yml`
```yaml
# ~/.surreal.yml
...
cluster_definition: <path to cluster_name.tf.json>
...
```

* Specify `kurreal_metadata_folder`, which is where book keeping information about a launched experiment will be stored.

* You need to specify the `kurreal_results_folder`, which is where experiment results will be stored (`<kurreal_results_folder>/<experiment_name>`). Note that this is a path on the container.

* (Optional, Recommended) `nfs`. Because the storage on a container is ephemeral, it is recommended that you create a network file system and mount it onto every container of your experiment. See [guide on creating nfs on clouds](nfs_on_cloud.md) and [this guide on setting up nfs with Surreal Kubernets mode](yaml_config.md#nfs).

* To launch an experiment on the cloud, you also need to configure the `creation_settings` field in `.surreal.yml`. This allows you to choose how to schedule things, etc. The first settings in the template is provided here. For details about creation settings, check [the documentation](creation_settings.md).
* With everything setup. You can use the `kurreal` commandline to create the distributed experiment. 
```bash
kurreal create cpu-experiment my-first-experiment
kurreal p # wait until kurreal p shows everything to be running
kurreal tensorboard
```
For more creation customization and more information about `kurreal`, see [kurreal documentation](kurreal.md).

After you are done, delete the experiment.
```bash
kurreal delete
```

## Setup Custom Docker Build Process
To develop a distributed application and run on Kubernetes, you need to build your own docker image. We provide docker builder (powered by [Symphony](https://github.com/SurrealAI/symphony)) that puts together a docker build environment from multiple locations in your file system. 

### Installation
* Install [Docker](https://www.docker.com)
* Obtain Surreal base image. This image take ~10G space.
```bash
docker pull surrealai/surreal-nvidia:v0.0
```
* Prepare your own docker registry to host your custom images. You need to put your custom images in a registry that is accessible from your Kubernetes cluster.
    - If you are using Google Cloud with project-id (i.e. myproject-123456), you can push-pull from Google Cloud's container registry: `us.gcr.io/<project-id>/<repo>:tag`. You do need to configure your own docker to have the credentials to read/write from the google hosted registry, see [documentation](https://cloud.google.com/sdk/gcloud/reference/auth/configure-docker).
```bash
gcloud auth configure-docker
```

## Develop Algorithms on Kubernetes
!! This section is under construction, surrealers please move on to the next section
Note: If you want to change the Surreal library, please refer to [Develop Surreal on Kubernetes](#developing-surreal-on-kubernetes).

To develop your own RL library using surreal. You need to do two things:
* First, you need to setup the build process which builds an image containing your own library.
* Second, you need to tell kurreal how to find your executable.

## Develop Surreal on Kubernetes
Note: If you are using Surreal but not changing the Surreal library itself, please refer to [Develop Algorithms on Kubernetes](#developing-algorithms-on-kubernetes).

We provide launch settings and docker build settings that build an image with your custom Surreal Library. To use them, you need to first setup the following fields (`<enclosed by brackets>`) in `~/.surreal.yml`.

```yaml
# ~/.surreal.yml
creation_settings:
  contrib:
    mode: basic
    ...
    agent:
      image: <my-registry>/<repo-name>
      build_image: contrib-image
      ...
    nonagent:
      image: <my-registry>/<repo-name>
      build_image: contrib-image
      ...

docker_build_settings:
  - name: contrib-image
    temp_directory: <~/symph_temp/contrib or anywhere you want image build to happen>
    verbose: true
    dockerfile: <path to your surreal fork>/docker/Dockerfile-contribute
    context_directories:
      - name: surreal
        path: <path to your surreal fork>
        force_update: true
```
For reference, here are the contents in `Dockerfile-contribute`
```
FROM 
# ~/surreal/docker/Dockerfile-contribute
COPY surreal /mylibs/surreal-dev
RUN pip install -e -U /mylibs/surreal-dev
```

Now `kurreal` will automatically build your image, push it and refer to them properly in launched experiments.
```bash
kurreal create contrib ...
```

## Reporting Issues

## Contributing

